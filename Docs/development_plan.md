# План разработки: Автоматизация обработки счетов

## Обзор проекта
Система автоматической обработки счетов с использованием Yandex Cloud Functions, OpenAI API и интеграции с Google Sheets.

---

## Этап 1: Подготовка инфраструктуры и учетных данных
**Цель:** Получить все необходимые доступы и API-ключи

### Задачи:
1. **Yandex Cloud**
   - [ ] Зарегистрировать аккаунт в Yandex Cloud
   - [ ] Создать облако и каталог
   - [ ] Получить OAuth-токен Яндекс.Диска
   - [ ] Создать структуру папок на Яндекс.Диске:
     - `/Входящие`
     - `/Обработанные`
     - `/Ошибки`

2. **OpenAI & Google Cloud**
   - [ ] Зарегистрироваться на OpenAI Platform (https://platform.openai.com)
   - [ ] Получить API-ключ OpenAI
   - [ ] Настроить биллинг и лимиты (рекомендуется установить monthly limit)
   - [ ] Создать проект в Google Cloud Console
   - [ ] Создать Service Account для Google Sheets API
   - [ ] Скачать JSON-ключ Service Account
   - [ ] Включить Google Sheets API для проекта

3. **Google Sheets**
   - [ ] Создать таблицу для хранения данных
   - [ ] Настроить структуру колонок (25 полей):

     **Информация о документе:**
     - Номер счета
     - Дата счета

     **Реквизиты получателя (продавца):**
     - Банк получателя
     - ИНН получателя
     - КПП получателя
     - Получатель платежа
     - БИК
     - Корр. счет
     - Расч. счет

     **Реквизиты покупателя:**
     - Покупатель
     - ИНН покупателя
     - КПП покупателя

     **Логистика:**
     - Грузополучатель
     - Грузоотправитель

     **Товары/Услуги (по строке):**
     - Наименование товара
     - Ед. изм.
     - Количество
     - Цена за ед.
     - Сумма
     - Ставка НДС (%)
     - Сумма НДС

     **Итоги документа:**
     - Сумма без НДС
     - Сумма НДС всего
     - Итого к оплате

     **Служебные:**
     - Статус (На проверку/ОК)
     - Ссылка на файл

   - [ ] Предоставить доступ Service Account к таблице

**Длительность:** 2-3 часа
**Зависимости:** Нет

---

## Этап 2: Настройка локальной разработки
**Цель:** Подготовить окружение для разработки и тестирования

### Задачи:
1. **Структура проекта**
   ```
   vibe_count/
   ├── src/
   │   ├── main.py              # Главный обработчик
   │   ├── file_processor.py    # Логика работы с файлами
   │   ├── llm_handler.py       # Интеграция с Gemini
   │   ├── sheets_writer.py     # Запись в Google Sheets
   │   ├── validator.py         # Валидация данных
   │   └── config.py            # Конфигурация и константы
   ├── tests/
   │   ├── test_files/          # Тестовые документы
   │   └── test_*.py            # Unit-тесты
   ├── requirements.txt
   ├── .env.example
   ├── .gitignore
   └── README.md
   ```

2. **Python окружение**
   - [ ] Создать виртуальное окружение
   - [ ] Создать requirements.txt с зависимостями:
     ```
     yandex-disk
     openai
     gspread
     google-auth
     python-docx
     pandas
     openpyxl
     Pillow
     python-dotenv
     ```
   - [ ] Установить зависимости

3. **Конфигурация**
   - [ ] Создать .env.example с шаблоном переменных
   - [ ] Создать .env с реальными ключами (добавить в .gitignore)
   - [ ] Настроить config.py для загрузки переменных окружения

**Длительность:** 1 час
**Зависимости:** Этап 1

---

## Этап 3: Разработка модуля работы с файлами
**Цель:** Реализовать сканирование и управление файлами на Яндекс.Диске

### Задачи:
1. **file_processor.py**
   - [ ] Функция подключения к Яндекс.Диску
   - [ ] Функция сканирования папки `/Входящие`
   - [ ] Фильтрация файлов (игнорирование `000_*`)
   - [ ] Функция определения типа файла (JPG/PNG/PDF/DOCX/XLSX)
   - [ ] Функция скачивания файла во временную директорию
   - [ ] Функция перемещения файла:
     - В `/Обработанные/ГОД/МЕСЯЦ` (с созданием структуры)
     - В `/Ошибки` при ошибке
   - [ ] Функция генерации публичной ссылки на файл

2. **Обработка текстовых файлов**
   - [ ] Извлечение текста из DOCX
   - [ ] Извлечение текста из XLSX
   - [ ] Форматирование для отправки в LLM

**Длительность:** 4-5 часов
**Зависимости:** Этап 2

---

## Этап 4: Разработка интеграции с LLM
**Цель:** Реализовать извлечение данных через OpenAI API

### Задачи:
1. **llm_handler.py**
   - [ ] Настройка клиента OpenAI API
   - [ ] Создать системный промпт для извлечения данных:
     ```
     Ты — эксперт по извлечению структурированных данных из бухгалтерских документов
     (счета на оплату, накладные, УПД). Твоя задача — проанализировать предоставленный
     файл и извлечь данные в строгом формате JSON.

     ПРАВИЛА ИЗВЛЕЧЕНИЯ:
     1. Если поле отсутствует в документе, установи значение null.
     2. Даты приведи к формату "DD.MM.YYYY".
     3. Числовые значения очисти от пробелов и символов валют (например, "10 000,00" -> 10000.00).
     4. Для табличной части товаров/услуг найди начало таблицы и извлеки все строки.

     СТРУКТУРА JSON:
     {
       "document_info": {
         "invoice_number": "Номер счета",
         "invoice_date": "Дата выставления (DD.MM.YYYY)"
       },
       "recipient_details": {
         "bank_name": "Банк получателя",
         "inn": "ИНН получателя",
         "kpp": "КПП получателя",
         "payee_name": "Получатель платежа",
         "bic": "БИК",
         "corr_account": "Корреспондентский счет",
         "current_account": "Расчетный счет"
       },
       "buyer_details": {
         "name": "Покупатель",
         "inn": "ИНН покупателя",
         "kpp": "КПП покупателя"
       },
       "logistics": {
         "consignee": "Грузополучатель",
         "consignor": "Грузоотправитель"
       },
       "items": [
         {
           "name": "Наименование",
           "unit": "Ед. изм.",
           "quantity": число,
           "price_unit": число,
           "total_sum": число,
           "vat_rate": число (например, 20 для 20%),
           "vat_amount": число
         }
       ],
       "totals": {
         "total_without_vat": число,
         "total_vat": число,
         "total_amount": число
       }
     }

     Верни только валидный JSON без markdown-разметки.
     ```
   - [ ] Функция обработки изображений (JPG/PNG/PDF) через GPT-4o с Vision
   - [ ] Функция обработки текста (DOCX/XLSX) через GPT-4 Turbo
   - [ ] Использование JSON mode (`response_format: {type: "json_object"}`)
   - [ ] Обработка ответа и парсинг JSON
   - [ ] Обработка ошибок API (retry логика, rate limits, тайм-ауты)

2. **Тестирование**
   - [ ] Тест на реальных сканах счетов
   - [ ] Тест на текстовых документах
   - [ ] Проверка качества распознавания
   - [ ] Тестирование разных моделей (gpt-4o vs gpt-4-turbo)

**Длительность:** 5-6 часов
**Зависимости:** Этап 2

---

## Этап 5: Разработка валидации данных
**Цель:** Обеспечить базовую проверку корректности извлеченных данных

### Задачи:
1. **validator.py**
   - [ ] Валидация формата даты (DD.MM.YYYY)
   - [ ] Проверка заполнения обязательных полей:
     - document_info (invoice_number, invoice_date)
     - recipient_details (inn, payee_name)
     - items (минимум 1 товар)
   - [ ] Математические проверки для каждого товара:
     - `price_unit × quantity = total_sum` (±0.01 допуск на округление)
     - `total_sum × (vat_rate / 100) = vat_amount` (±0.01)
   - [ ] Проверка итоговых сумм документа:
     - `∑ items[].total_sum = total_without_vat` (±0.01)
     - `∑ items[].vat_amount = total_vat` (±0.01)
     - `total_without_vat + total_vat = total_amount` (±0.01)
   - [ ] Проверка диапазонов (quantity > 0, price_unit > 0, vat_rate ∈ [0, 20])
   - [ ] Валидация ИНН (10 или 12 цифр)
   - [ ] Функция логирования предупреждений с уровнями (ERROR/WARNING)

**Длительность:** 3-4 часа
**Зависимости:** Этап 4

---

## Этап 6: Разработка модуля записи в Google Sheets
**Цель:** Сохранить извлеченные данные в таблицу

### Задачи:
1. **sheets_writer.py**
   - [ ] Подключение к Google Sheets через Service Account
   - [ ] Функция "уплощения" JSON в плоские строки:
     - Каждый товар из `items[]` → отдельная строка
     - Дублирование общих полей (document_info, recipient_details, buyer_details, logistics)
     - Добавление итогов (totals) в каждую строку
   - [ ] Маппинг полей JSON → колонки таблицы (25 колонок):
     ```python
     row = [
       invoice_number, invoice_date,
       bank_name, inn_recipient, kpp_recipient, payee_name, bic, corr_account, current_account,
       buyer_name, inn_buyer, kpp_buyer,
       consignee, consignor,
       item_name, unit, quantity, price_unit, item_total, vat_rate, vat_amount,
       total_without_vat, total_vat, total_amount,
       status, file_link
     ]
     ```
   - [ ] Функция добавления строк в таблицу (batch append)
   - [ ] Добавление статуса "На проверку"
   - [ ] Добавление ссылки на оригинальный файл на Яндекс.Диске
   - [ ] Форматирование чисел (2 знака после запятой)
   - [ ] Обработка ошибок записи

2. **Тестирование**
   - [ ] Тест записи документа с одним товаром
   - [ ] Тест записи счета с несколькими товарами (проверка дублирования общих полей)
   - [ ] Тест записи документа с null значениями
   - [ ] Проверка корректности форматирования и выравнивания

**Длительность:** 4-5 часов
**Зависимости:** Этап 3, 5

---

## Этап 7: Интеграция всех компонентов
**Цель:** Объединить все модули в единый пайплайн

### Задачи:
1. **main.py**
   - [ ] Функция-обработчик для Cloud Function:
     ```python
     def handler(event, context):
         # 1. Сканирование /Входящие
         # 2. Выбор первого файла
         # 3. Определение типа
         # 4. Обработка через LLM
         # 5. Валидация
         # 6. Запись в Sheets
         # 7. Архивация файла
         # 8. Обработка ошибок
     ```
   - [ ] Логирование всех этапов
   - [ ] Try-catch блоки для каждого этапа
   - [ ] Возврат статуса выполнения

2. **Логика очереди**
   - [ ] Обработка строго одного файла за запуск
   - [ ] Проверка на отсутствие файлов (graceful exit)

**Длительность:** 3-4 часа
**Зависимости:** Этапы 3-6

---

## Этап 8: Локальное тестирование
**Цель:** Убедиться, что система работает end-to-end

### Задачи:
1. **Подготовка тестовых данных**
   - [ ] Собрать 5-10 тестовых счетов разных форматов
   - [ ] Загрузить их в `/Входящие` на Яндекс.Диске

2. **Запуск и проверка**
   - [ ] Запустить main.py локально
   - [ ] Проверить логи выполнения
   - [ ] Проверить данные в Google Sheets
   - [ ] Проверить перемещение файлов в архив
   - [ ] Тест обработки файла с ошибкой (`000_*`)
   - [ ] Тест обработки некорректного файла

3. **Отладка**
   - [ ] Исправить найденные баги
   - [ ] Улучшить обработку edge cases

**Длительность:** 4-5 часов
**Зависимости:** Этап 7

---

## Этап 9: Деплой в Yandex Cloud Functions
**Цель:** Развернуть систему в продакшн

### Задачи:
1. **Подготовка к деплою**
   - [ ] Создать ZIP-архив с кодом и requirements.txt
   - [ ] Убрать .env файл (использовать переменные окружения Cloud)

2. **Создание Cloud Function**
   - [ ] Создать функцию в Yandex Cloud Console
   - [ ] Загрузить код
   - [ ] Настроить переменные окружения (API-ключи, токены)
   - [ ] Указать точку входа: `main.handler`
   - [ ] Установить тайм-аут: 120 секунд
   - [ ] Выделить память: 512 MB

3. **Настройка триггера**
   - [ ] Создать Timer Trigger (Cron)
   - [ ] Установить расписание: каждые 5-10 минут
   - [ ] Привязать к функции

4. **Проверка работы**
   - [ ] Загрузить тестовый файл в `/Входящие`
   - [ ] Дождаться срабатывания триггера
   - [ ] Проверить логи в Cloud Console
   - [ ] Проверить результат в Google Sheets

**Длительность:** 2-3 часа
**Зависимости:** Этап 8

---

## Этап 10: Мониторинг и оптимизация
**Цель:** Обеспечить стабильную работу системы

### Задачи:
1. **Настройка мониторинга**
   - [ ] Включить Cloud Logging
   - [ ] Настроить алерты на ошибки
   - [ ] Создать дашборд для отслеживания метрик:
     - Количество обработанных файлов
     - Количество ошибок
     - Среднее время обработки

2. **Оптимизация**
   - [ ] Проанализировать время выполнения каждого этапа
   - [ ] Оптимизировать медленные участки
   - [ ] Тестирование на реальной нагрузке (~150 документов/месяц)

3. **Документация**
   - [ ] Обновить README.md с инструкциями по деплою
   - [ ] Документировать процесс добавления новых типов документов
   - [ ] Создать инструкцию для пользователя (как работать со статусами)

**Длительность:** 2-3 часа
**Зависимости:** Этап 9

---

## Этап 11: Обучение и запуск в продакшн
**Цель:** Передать систему в эксплуатацию

### Задачи:
1. **Human-in-the-Loop процесс**
   - [ ] Создать чеклист для проверки данных
   - [ ] Обучить пользователя работе с таблицей
   - [ ] Настроить уведомления о новых записях (опционально)

2. **Пилотный запуск**
   - [ ] Запустить систему на 1 неделю
   - [ ] Ежедневно проверять точность распознавания
   - [ ] Собрать обратную связь

3. **Финальная настройка**
   - [ ] Скорректировать промпты на основе ошибок
   - [ ] Добавить дополнительную валидацию при необходимости
   - [ ] Полный запуск в продакшн

**Длительность:** 1 неделя (с учетом наблюдения)
**Зависимости:** Этап 10

---

## Общая оценка времени

| Этап | Длительность | Тип работы |
|------|--------------|------------|
| 1. Инфраструктура | 2-3 часа | Настройка |
| 2. Локальная разработка | 1 час | Настройка |
| 3. Модуль работы с файлами | 4-5 часов | Разработка |
| 4. Интеграция с LLM | 5-6 часов | Разработка |
| 5. Валидация данных | 3-4 часа | Разработка |
| 6. Запись в Google Sheets | 4-5 часов | Разработка |
| 7. Интеграция компонентов | 3-4 часа | Разработка |
| 8. Локальное тестирование | 4-5 часов | Тестирование |
| 9. Деплой в Cloud | 2-3 часа | Деплой |
| 10. Мониторинг и оптимизация | 2-3 часа | Оптимизация |
| 11. Запуск в продакшн | 1 неделя | Пилот |

**Итого разработки:** 30-38 часов чистого времени
**С учетом пилота:** ~2 недели календарного времени

---

## Риски и митигация

### Риск 1: Низкая точность распознавания LLM
**Вероятность:** Средняя
**Митигация:**
- Тщательная разработка промптов с примерами
- A/B тестирование разных моделей (gpt-4o vs gpt-4-turbo)
- Использование JSON mode для структурированного вывода
- Human-in-the-Loop проверка всех записей

### Риск 2: Превышение бюджета OpenAI API
**Вероятность:** Средняя (в зависимости от объема)
**Митигация:**
- Установка месячных лимитов в OpenAI Dashboard
- Мониторинг использования API и затрат
- Оптимизация размера передаваемых изображений
- Использование более дешевых моделей для текста (gpt-4-turbo вместо gpt-4o где возможно)
- Кеширование для повторных обработок
- **Примерная стоимость:** ~$5-15/месяц при 150 документах

### Риск 3: Таймауты Cloud Function
**Вероятность:** Низкая
**Митигация:**
- Обработка одного файла за запуск
- Увеличение тайм-аута до 120 сек
- Асинхронная обработка тяжелых операций

### Риск 4: Проблемы с форматами документов
**Вероятность:** Средняя
**Митигация:**
- Тщательное тестирование на реальных данных
- Гибкие парсеры для разных структур
- Fallback на ручную обработку в папке `/Ошибки`

---

## Критерии успеха

- ✅ Система автоматически обрабатывает 95%+ документов
- ✅ Точность извлечения данных 90%+ (с учетом human проверки)
- ✅ Среднее время обработки < 60 секунд на документ
- ✅ Время на ручную проверку < 5 минут в день
- ✅ Минимальные затраты на инфраструктуру (~$5-15/мес для OpenAI API, Yandex Cloud в Free Tier)

---

## Следующие шаги

1. Утвердить план разработки
2. Начать с Этапа 1 (получение доступов)
3. Создать Git-репозиторий и настроить структуру проекта
4. Приступить к разработке по этапам

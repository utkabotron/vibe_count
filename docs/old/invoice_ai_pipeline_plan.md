# Архитектура решения

- **Источник данных**  
  - Папка `SS` на диске.  
  - Скрипт регулярно сканирует папку и находит новые файлы (по имени/хэшу/времени модификации).  

- **Препроцессинг файлов**  
  - Определение типа: `pdf`, `jpg/png`, `xlsx`, `docx`, возможно `html/eml`.  
  - Для текстовых PDF/доков — вытаскиваем текст.  
  - Для сканов/фото — OCR (через Tesseract или через OpenAI Vision-модель).  

- **AI‑извлечение реквизитов**  
  - Вызов OpenAI Chat/JSON mode: на вход – сырой текст счета (и метаданные), на выход – JSON c полями:  
    - `payment_date`, `organization`, `counterparty`, `amount`,  
    - `purpose`,  
    - `bank_type` ∈ {`ALFA`, `SBER`, `TOCHKA`}.  
  - Четкий system prompt, чтобы модель ВСЕГДА возвращала ровно эти поля.  

- **Постобработка и валидация**  
  - Нормализация даты к формату `YYYY-MM-DD`.  
  - Преобразование суммы к числу с точкой.  
  - Проверка, что `bank_type` одна из трёх; если нет — логируем как “требует ручной проверки”.  

- **Запись в Google Sheets**  
  - Подключение через сервисный аккаунт.  
  - Одна строка = один счет, плюс служебные поля: имя файла, путь, дата обработки, статус.  

- **Оркестрация**  
  - Консольный скрипт `main.py`, который:  
    - читает конфиг (`.env`),  
    - сканирует папку,  
    - обрабатывает новые файлы,  
    - пишет результат в Google Sheet,  
    - логирует ошибки.  
  - Запуск либо как долгоживущий процесс, либо через `cron`/`launchd` раз в N минут.

---

## Пошаговый план с оценкой сложности

Оценка сложности:  
L = низкая, M = средняя, H = высокая (по времени/рискам).

1. **Подготовка окружения и репозитория (L)**  
   - Установить Python 3.11+.  
   - Создать виртуальное окружение, `requirements.txt`.  
   - Подготовить `.env` для ключей и настроек.  

2. **Google Sheets: доступ и базовая интеграция (M)**  
   - Создать проект в Google Cloud, включить Sheets API.  
   - Создать сервисный аккаунт, получить JSON‑ключ.  
   - Создать/выбрать Google-таблицу, выдать доступ сервисному аккаунту.  
   - Написать простой код “добавить строку в таблицу”.  
   - Риски: возня с авторизацией и правами (обычно 1–3 часа).

3. **Дизайн структуры данных и таблицы (L)**  
   - Определить финальный набор колонок, например:  
     - `file_name`, `file_path`, `processed_at`,  
     - `payment_date`, `organization`, `counterparty`, `amount`, `purpose`, `bank_type`,  
     - `status`, `raw_text_link` (опционально).  
   - Создать эти колонки в первой строке таблицы.

4. **Модуль сканирования папки и учета обработанных файлов (M)**  
   - Сканировать `SS` рекурсивно, собирать список файлов с нужными расширениями.  
   - Хранить “реестр обработанных”:  
     - либо в локальной SQLite,  
     - либо в JSON (`processed_files.json`) с хэшами/mtime,  
     - либо в самой Google-таблице (колонка `file_name`).  
   - Логика: “если файла ещё нет в реестре — обработать”.  

5. **Препроцессинг форматов счетов (M–H)**  
   - Для `pdf`:  
     - Пытаться достать текст через `pypdf`.  
     - Если текста почти нет — конвертировать страницы в изображения (`pdf2image`) и гонять через OCR.  
   - Для `jpg/png`:  
     - OCR по картинке.  
   - Для `docx/xlsx`:  
     - `python-docx`, `openpyxl`.  
   - Это самый “скользкий” шаг, т.к. форматы могут быть очень разные; понадобится итеративная доводка.  

6. **Интеграция с OpenAI: промпт и JSON‑ответ (M)**  
   - Выбрать модель:  
     - для только текста — `gpt-4o-mini` (дешевле) или аналог;  
     - для картинок/сканов можно сразу использовать Vision‑возможности, чтобы не ставить Tesseract.  
   - Сформулировать жесткий system prompt:  
     - описать поля, примеры, требования к формату (строго JSON).  
   - Написать функцию `extract_invoice_fields(raw_text) -> dict` с ретраями и обработкой ошибок.  
   - Протестировать на нескольких реальных счетах из папки `SS`.

7. **Постобработка и валидация данных (L–M)**  
   - Нормализация даты: парсинг типичных русских форматов (`01.11.2025`, `2025-11-01`, и т.д.).  
   - Преобразование сумм (`1 234,56` → `1234.56`).  
   - Нормализация банка: например, модель может вернуть “АО «Альфа-Банк»”, надо привести к `ALFA`.  
   - Логирование кейсов, где что-то не распарсилось.  

8. **Запись результата в Google Sheets (L)**  
   - Маппинг dict → список значений по колонкам.  
   - Добавление строки в конец таблицы.  
   - Защита от дублей: перед вставкой можно проверять по `file_name`.  

9. **Организация запуска: сервис/крон + логирование (L–M)**  
   - Вариант 1 (проще): скрипт запускается по расписанию (cron/launchd) раз в 5–10 минут, обрабатывает новые файлы и завершается.  
   - Вариант 2: долгоживущий процесс с `watchdog`, реагирующий на появление новых файлов.  
   - Добавить логирование в файл: успешные обработки / ошибки.  

10. **Тестирование на реальных данных и доводка промпта (M)**  
    - Прогнать на десятке реальных счетов.  
    - Посмотреть типичные ошибки, поправить промпт и постобработку.  
    - При необходимости разбить пайплайн на шаги: отдельно OCR → отдельно AI → отдельно Sheets.

---

## Рекомендуемый стек

- **Язык и окружение**  
  - Python 3.11+  
  - `venv` или `poetry` для зависимостей.  

- **Работа с файлами**  
  - Стандартная библиотека: `os`, `pathlib`, `glob`.  
  - Для мониторинга (опционально): `watchdog`.  

- **PDF/документы/изображения**  
  - `pypdf` (или `pypdf2`) – текст из PDF.  
  - `pdf2image` + `poppler` – конвертация PDF в изображения (если нужен OCR).  
  - `pytesseract` + установленный `tesseract-ocr` (через `brew install tesseract`) – OCR.  
  - `python-docx`, `openpyxl` – если есть docx/xlsx.  

- **OpenAI API**  
  - Официальная библиотека `openai` (новая, с `OpenAI()` клиентом).  
  - Модель:  
    - текст: `gpt-4o-mini` (дешево/быстро),  
    - если удобнее без отдельного OCR – использовать vision-способности модели, подав изображения/страницы напрямую.  

- **Google Sheets**  
  - `gspread`  
  - `google-auth` / `google-auth-oauthlib` для авторизации сервисного аккаунта.  

- **Конфиг и утилиты**  
  - `python-dotenv` – загрузка `.env` (ключ API, путь к папке, ID таблицы).  
  - `loguru` или стандартный `logging` – логирование.  
  - (Опционально) `pandas` – если захочешь локально анализировать выгрузку.  

---

## Итог

- Описана архитектура, пошаговый план с оценкой сложности и стек (Python + OpenAI + Google Sheets), который вписывается в требования.  
- Следующий шаг:  
  - либо начать с минимального варианта (только PDF + текст + OpenAI + запись в Sheets) и потом добавлять OCR/другие форматы,  
  - либо спроектировать структуру репозитория и написать каркас `main.py` + модулей.